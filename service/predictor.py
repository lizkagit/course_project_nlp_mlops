import joblib
import numpy as np
from typing import Dict, Any
import time
import os
import sys

# Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ ÐºÐ¾Ñ€ÐµÐ½ÑŒ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ð° Ð² Ð¿ÑƒÑ‚ÑŒ
current_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(current_dir)
sys.path.insert(0, project_root)

try:
    from config_loader import config
    HAS_CONFIG = True
except ImportError:
    HAS_CONFIG = False
    print("âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑŽ")

class ModelPredictor:
    def __init__(self, model_path: str = None, vectorizer_path: str = None):
        self.model = None
        self.vectorizer = None
        self.is_loaded = False
        
        # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ð¿ÑƒÑ‚Ð¸ Ð¸Ð· ÐºÐ¾Ð½Ñ„Ð¸Ð³Ð° ÐµÑÐ»Ð¸ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½Ñ‹
        if model_path is None and HAS_CONFIG:
            model_path = config.get_inference_config().model.model_path
        elif model_path is None:
            model_path = "service_models/best_model.pkl"
            
        if vectorizer_path is None and HAS_CONFIG:
            vectorizer_path = config.get_inference_config().model.vectorizer_path
        elif vectorizer_path is None:
            vectorizer_path = "service_models/tfidf_vectorizer.pkl"
        
        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ð±ÑÐ¾Ð»ÑŽÑ‚Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸
        if not os.path.isabs(model_path):
            model_path = os.path.join(current_dir, model_path)
        if not os.path.isabs(vectorizer_path):
            vectorizer_path = os.path.join(current_dir, vectorizer_path)
        
        print(f"ðŸ”„ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸Ð·: {model_path}")
        print(f"ðŸ”„ Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð°Ð¹Ð·ÐµÑ€ Ð¸Ð·: {vectorizer_path}")
        
        self.load(model_path, vectorizer_path)
    
    
    def load(self, model_path: str, vectorizer_path: str) -> bool:
        """Ð—Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ Ð²ÐµÐºÑ‚Ð¾Ñ€Ð°Ð¹Ð·ÐµÑ€"""
        try:
            self.model = joblib.load(model_path)
            self.vectorizer = joblib.load(vectorizer_path)
            self.is_loaded = True
            print(f"âœ… ÐœÐ¾Ð´ÐµÐ»ÑŒ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð° ÑƒÑÐ¿ÐµÑˆÐ½Ð¾")
            print(f"   Ð¢Ð¸Ð¿ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {type(self.model).__name__}")
            print(f"   Ð Ð°Ð·Ð¼ÐµÑ€ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ: {len(self.vectorizer.vocabulary_)} ÑÐ»Ð¾Ð²")
            return True
        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {e}")
            self.is_loaded = False
            return False
    
    def predict(self, text: str) -> Dict[str, Any]:
        """Ð”ÐµÐ»Ð°ÐµÑ‚ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð¾Ð´Ð½Ð¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
        start_time = time.time()
        
        if not self.is_loaded:
            return {
                "prediction": 0.0,
                "error": "Model not loaded",
                "processing_time_ms": 0
            }
        
        try:
            # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ‚ÐµÐºÑÑ‚ Ð² Ñ„Ð¸Ñ‡Ð¸
            features = self.vectorizer.transform([text])
            
            # Ð”ÐµÐ»Ð°ÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ
            prediction = float(self.model.predict(features)[0])
            
            # Ð’Ñ€ÐµÐ¼Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸
            processing_time = (time.time() - start_time) * 1000
            
            return {
                "prediction": prediction,
                "processing_time_ms": round(processing_time, 2),
                "features_count": features.shape[1],
                "error": None
            }
            
        except Exception as e:
            return {
                "prediction": 0.0,
                "processing_time_ms": 0,
                "error": str(e)
            }
    
    def batch_predict(self, texts: list) -> list:
        """ÐŸÑ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ð´Ð»Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ñ… Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
        return [self.predict(text) for text in texts]
    
    def get_model_info(self) -> Dict[str, Any]:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾ Ð¼Ð¾Ð´ÐµÐ»Ð¸"""
        if not self.is_loaded:
            return {"is_loaded": False}
        
        return {
            "is_loaded": True,
            "model_type": type(self.model).__name__,
            "vocabulary_size": len(self.vectorizer.vocabulary_),
            "model_params": str(self.model.get_params()) if hasattr(self.model, 'get_params') else "Unknown"
        }