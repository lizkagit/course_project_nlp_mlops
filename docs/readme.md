## Проект: Анализ тональности текстов о метро (MLOps Pipeline)

Проект представляет собой MLOps-решение для анализа тональности текстовых отзывов о метрополитене. Включает модель машинного обучения, несколько вариантов сервисов для инференса и UI-интерфейс.

##  Структура проекта

```
.
├── .env                         # Переменные окружения
├── configs/                     # Конфигурационные файлы
│   ├── inference_config.yaml    # Конфиг для инференса
│   └── train_config.yaml       # Конфиг для обучения
├── data/                        # Данные
│   ├── processed/              # Обработанные данные
│   ├── experiments/            # Эксперименты
│   │   └── exp1_regress.csv   # Датасет для экпериментов предобработанный
│   ├── df_capped_csv          # Урезанный датасет (95 перцентиль)
│   └── raw/                    # Исходные данные
│       ├── all_posts_v1.csv   # Все посты
│       └── df_mosmetro_sample.csv  # Выборка по целевой группе
├── docs/                        # Документация
│   ├── DATASET_CARD.md         # Карточка датасета
│   ├── MODEL_CARD.md           # Карточка модели
│   └── readme.md              # Основная документация                  
├── notebooks/               
│   ├── models/                 # Сохраненные модели с экперементов
│   ├── service_models/         # Модели для сервисов(лучшие)
│   ├── course_mlops.ipynb     # Основной ноутбук
│   └── models_summary.csv  # Сравнение экспериментов
├── service/                     # Сервисы  
│   ├── models/                 # Модели для сервисов
│   ├── api.py                  # FastAPI сервис
│   ├── gradio_ui.py                # Веб-интерфейс на Gradio
│   ├── Dockerfile                   # Docker-образ
│   ├── requirements.txt            # Основные зависимости
│   ├── predictor.py                # Модуль для предсказаний
│   └── bentoml_service.py     # BentoML сервис
├── dockerignore                # Исключения для Docker
├── .gitignore                  # Исключения для Git
├── config_loader.py            # Загрузчик конфигов
├── docker-compose.yml          # Docker Compose конфигурация
├── requirements-dev.txt        # Зависимости для разработки
├── test_metro_apis.py          # Тестирование API
└── run.sh                      # Скрипт запуска (основной)
```


### Вариант 1: Запуск через скрипт  

```bash
./run.sh
```
Скрипт `run.sh` автоматически выполнит следующие шаги:
1. Остановит и удалит старые контейнеры (если существуют)
2. Удалит старые образы
3. Соберет новый Docker-образ
4. Запустит контейнер с тремя сервисами одновременно
5. Проверит статус запуска

### Вариант 2: Ручной запуск
```bash
# Сборка образа
docker build --no-cache -t mlops-api -f service/Dockerfile .

# Запуск контейнера
docker run -d \
  -p 8000:8000 \
  -p 3000:3000 \
  -p 7860:7860 \
  --name mlops-full \
  mlops-api:latest
```

После успешного запуска будут доступны:

| Сервис | URL | Порт | Описание |
|--------|-----|------|----------|
| **FastAPI** | http://localhost:8000 | 8000 | Основной API сервис |
| **FastAPI Docs** | http://localhost:8000/docs | 8000 | Интерактивная документация Swagger |
| **BentoML** | http://localhost:3000 | 3000 | Альтернативный сервис на BentoML |
| **Gradio UI** | http://localhost:7860 | 7860 | Веб-интерфейс для тестирования |

## Тестирование API

Для проверки работы сервисов используйте готовый скрипт:

```bash
python test_metro_apis.py
```

Скрипт протестирует оба API (FastAPI и BentoML) с различными текстами о метро и покажет:
- Статус ответа
- Результаты предсказаний
- Время выполнения

### Структура конфигурации

- `configs/train_config.yaml` — параметры обучения модели
- `configs/inference_config.yaml` — параметры инференса


### Модели

- Основная модель: находится в `notebooks/service_models/`
- Обучение: см. `notebooks/course_mlops.ipynb`
- Эксперименты: результаты в `notebooks/models_summary.csv`


Проект разработан в учебных целях в рамках курса MLOps.

