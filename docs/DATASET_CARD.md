# Dataset Card: Moscow Metro Posts Dataset

## Основная информация
- **Название**: VK_Posts_Raw Moscow Metro Dataset
- **Версия**: 1.0.3 (processed для экспериментов)
- **Dataset ID**: `968e6deded76478aa11984bc266a4126`
- **Язык**: Русский
- **Источник**: VK  (ВКонтакте)
- **Платформа**: Социальная сеть ВК
- **Тематика**: Московское метро 
- **Лицензия**: Исследовательская (некоммерческая)
 

## Происхождение данных
### Источник
- **Платформа**: VKontakte (ВКонтакте)
- **Группы**: Публичные сообщества о московском метро
- **Тип данных**: Публичные посты и комментарии

### Отобранные группы
| Группа | Отобрано постов | Всего комментов | Среднее комментов |
|--------|----------------|-----------------|-------------------|
| **mosmetro** | 7,937 | 272,011 | 34.27 |
| moscowmetro | 40,958 | 384,319 | 9.38 |
| gazetametro | 16,026 | 34,938 | 2.18 |
| mirmetro | 7,231 | 59,280 | 8.20 |

### Критерии отбора
1. **mosmetro** выбрана как основная группа, потому что:
   - Наибольшее количество ненулевых постов
   - Высокое соотношение комментариев/посты (272к комментов на 8к постов)
   - Активное сообщество с релевантным контентом
   - В отличие от moscowmetro (где 40к постов, но многие без текста)

## Структура исходных данных
### Raw Dataset (VK_Posts_Raw v1.0.1)
**Размер**: 72,152 строк × 11 колонок

| Колонка | Тип | Описание |
|---------|-----|----------|
| `post_id` | string | Уникальный идентификатор поста |
| `group_name` | string | Название группы (например, "mosmetro") |
| `group_display_name` | string | Отображаемое название группы |
| `text` | string | Полный текст поста |
| `comments_count` | int64 | Количество комментариев |
| `likes` | int64 | Количество лайков |
| `reposts` | int64 | Количество репостов |
| `views` | int64 | Количество просмотров |
| `date` | string | Дата публикации |
| `url` | string | Ссылка на пост |
| `text_length` | int64 | Длина текста в символах |

## Предобработка и фильтрация
### Этап 1: Выбор группы и периода
1. **Выбрана группа**: `mosmetro`
2. **Период**: 2017-2025 годы (отброшены 2014-2016)
   - Поведение пользователей 2014-2016 слабо коррелирует с современными привычками
   - 2017 год: резкий рост активности (+44% лайков, +30% комментов)
   - Данные 2017-2025 релевантны для прогнозирования

**Обработка выбросов**:
- Максимальное значение: 10,749 комментариев
- 95% перцентиль: 125 комментариев
- Максимум после обработки: 125
 
1. **Очистка текста**:
   - Удаление HTML-тегов, ссылок, упоминаний (@)
   - Нормализация пробелов и переносов строк
   - Удаление спецсимволов, эмодзи

2. **Лингвистическая обработка**:
   - Лемматизация (pymorphy3 для русского языка)
   - Удаление стоп-слов (русские стоп-слова)
   - Приведение к нижнему регистру
   - Удаление пунктуации

3. **TF-IDF векторизация**:
   - Максимальное количество признаков: 5,000
   - n-граммы: униграммы и биграммы (1-2)
   - min_df: 2 (слово должно встречаться минимум в 2 документах)
   - max_df: 0.85 (исключение слишком частых слов)
 
## Сплиты данных
### Разделение для экспериментов
```
Всего данных: 5,594 записей
├── Train Set: 5,035 записей (90%)
│   ├── Обучение: 4,532 записей
│   └── Валидация: 503 записи
└── Test Set: 559 записей (10%)
- **Случайное разбиение**: `random_state=42`
```
## Примеры данных
### Исходные посты (после очистки)
```
Текст: "осень хороший время горячее чай любимый произведение проект книга..."
Комментарии: 0

Текст: "технология который стоить место чат бот александр база знание..."
Комментарии: 1
```

### Локальные пути
```
Исходные данные: ../data/raw/vk_posts_raw.csv

Промежуточные:  ../data/raw/df_mosmetro_sample.csv
                ../data/processed/df_capped_.csv
Для экспериментов: ../data/processed/experiments/exp1_regres.csv
```

```markdown
## Data Pipeline

```
VK API/Scraping
     ↓
Raw VK Posts (72,152 posts)
     ↓
Group Selection (mosmetro) → 7,937 posts
     ↓
Year Filtering (2017-2025) → 5,905 posts
     ↓
Deduplication → 5,594 posts
     ↓
Capping (95th percentile)
     ↓
Text Cleaning & Lemmatization
     ↓
Split (90/10)
     ↓
TF-IDF Vectorization (5,000 features)
```